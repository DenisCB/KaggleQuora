{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-poster')\n",
    "sns.set_palette('Set1', 10, desat=0.75)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "from scipy.sparse import csr_matrix, coo_matrix,hstack, vstack\n",
    "DATA_PATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1_total_counts</th>\n",
       "      <th>q2_total_counts</th>\n",
       "      <th>sum_count</th>\n",
       "      <th>q1_counts_in_q1</th>\n",
       "      <th>q1_counts_in_q2</th>\n",
       "      <th>q2_counts_in_q1</th>\n",
       "      <th>q2_counts_in_q2</th>\n",
       "      <th>q1_in_q2_share</th>\n",
       "      <th>q2_in_q1_share</th>\n",
       "      <th>jaccard_dist_nbr_1</th>\n",
       "      <th>...</th>\n",
       "      <th>loc_city_match_num</th>\n",
       "      <th>loc_city_match_relative</th>\n",
       "      <th>loc_city_mismatch_num</th>\n",
       "      <th>loc_city_mismatch_relative</th>\n",
       "      <th>loc_q1_city_num</th>\n",
       "      <th>loc_q2_city_num</th>\n",
       "      <th>lgb_tfidf_oof</th>\n",
       "      <th>lgb_tfidfpca_oof</th>\n",
       "      <th>nnet_tfidf_oof</th>\n",
       "      <th>FM_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288244</td>\n",
       "      <td>0.306657</td>\n",
       "      <td>2.187292e-01</td>\n",
       "      <td>0.311618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293808</td>\n",
       "      <td>0.435092</td>\n",
       "      <td>1.393378e-01</td>\n",
       "      <td>0.302342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368330</td>\n",
       "      <td>0.593106</td>\n",
       "      <td>4.971907e-01</td>\n",
       "      <td>0.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>1.181926e-08</td>\n",
       "      <td>0.299354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.375343</td>\n",
       "      <td>3.728851e-02</td>\n",
       "      <td>0.315754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q1_total_counts  q2_total_counts  sum_count  q1_counts_in_q1  \\\n",
       "0                1                2        3.0                1   \n",
       "1                8                3       11.0                7   \n",
       "2                2                1        3.0                1   \n",
       "3                1                1        2.0                1   \n",
       "4                3                1        4.0                3   \n",
       "\n",
       "   q1_counts_in_q2  q2_counts_in_q1  q2_counts_in_q2  q1_in_q2_share  \\\n",
       "0                0              1.0                1        0.000000   \n",
       "1                1              2.0                1        0.142857   \n",
       "2                1              0.0                1        1.000000   \n",
       "3                0              0.0                1        0.000000   \n",
       "4                0              0.0                1        0.000000   \n",
       "\n",
       "   q2_in_q1_share  jaccard_dist_nbr_1    ...     loc_city_match_num  \\\n",
       "0             1.0                 0.0    ...                      0   \n",
       "1             2.0                 0.0    ...                      1   \n",
       "2             0.0                 0.0    ...                      0   \n",
       "3             0.0                 0.0    ...                      0   \n",
       "4             0.0                 0.0    ...                      0   \n",
       "\n",
       "   loc_city_match_relative  loc_city_mismatch_num  loc_city_mismatch_relative  \\\n",
       "0                     -1.0                      0                        -1.0   \n",
       "1                      0.5                      0                         0.0   \n",
       "2                     -1.0                      0                        -1.0   \n",
       "3                     -1.0                      0                        -1.0   \n",
       "4                      0.0                      1                         1.0   \n",
       "\n",
       "   loc_q1_city_num  loc_q2_city_num  lgb_tfidf_oof  lgb_tfidfpca_oof  \\\n",
       "0                0                0       0.288244          0.306657   \n",
       "1                1                1       0.293808          0.435092   \n",
       "2                0                0       0.368330          0.593106   \n",
       "3                0                0       0.000616          0.000598   \n",
       "4                1                0       0.056711          0.375343   \n",
       "\n",
       "   nnet_tfidf_oof    FM_oof  \n",
       "0    2.187292e-01  0.311618  \n",
       "1    1.393378e-01  0.302342  \n",
       "2    4.971907e-01  0.319215  \n",
       "3    1.181926e-08  0.299354  \n",
       "4    3.728851e-02  0.315754  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([pd.read_csv(os.path.join(DATA_PATH, 'train_nonNLP_features.csv')),\n",
    "                  pd.read_csv(os.path.join(DATA_PATH, 'train_NLP_features.csv')),\n",
    "                  pd.read_csv(os.path.join(DATA_PATH, 'train_pos_diff_matrix.csv')),\n",
    "                  pd.read_csv(os.path.join(DATA_PATH, 'train_PN.csv')),\n",
    "                  pd.read_csv(os.path.join(DATA_PATH, 'train_lgb_tfidf_oof.csv')),\n",
    "                  pd.read_csv(os.path.join(DATA_PATH, 'train_nnet_tfidf_oof.csv')),\n",
    "                  pd.read_csv(os.path.join(DATA_PATH, 'train_fm_oof.csv')),\n",
    "                 ], axis=1)#[:100000]\n",
    "\n",
    "target = pd.read_csv(os.path.join(DATA_PATH, 'target.csv')).target#[:100000]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove features uncorrelated with target and correlated with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 s, sys: 5.49 s, total: 41.6 s\n",
      "Wall time: 42.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = [col for col in data.columns if data[col].dtypes in ['int', 'float'] and col!='target']\n",
    "\n",
    "data['target'] = target\n",
    "features_to_drop = dict()\n",
    "feature_target_corrs = dict()\n",
    "\n",
    "# Fill the feature_target_corrs dict dictionary of correlations with target for each feature.\n",
    "# If feature-target correlation is closer to zero than 0.001, then the feature is removed.\n",
    "for feature in features:\n",
    "    correlation = data[['target', feature]].corr(method='spearman').iloc[0][1]\n",
    "    feature_target_corrs[feature] = correlation\n",
    "    if abs(correlation)<1e-3:\n",
    "        features_to_drop[feature] = correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of possible pairwise feature combinations 22791.0\n",
      "Actual number of calculations: 2648\n",
      "\n",
      "Initial number of features: 214\n",
      "Features dropped: 32\n",
      "Current number of features: 182\n",
      "CPU times: user 9min 43s, sys: 51.7 s, total: 10min 35s\n",
      "Wall time: 10min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_correlated_features(data, features, features_to_drop, feature_target_corrs, \n",
    "                            target_corr_difference_threshold, \n",
    "                            features_corr_threshold):\n",
    "    \"\"\"\n",
    "    imput:\n",
    "        data - pandas DataFrame with features and target\n",
    "        features - list of feature names to be tested. All of them must be contained in data\n",
    "        features_to_drop - dictionary with bad features\n",
    "        feature_target_corrs - dictionary, where feature names are the keys and their \n",
    "        correlations with target are values\n",
    "        target_corr_difference_threshold - float. If difference between two features correlation with \n",
    "        target is smaller than this value, then feature-feature correlation is calculated.\n",
    "        features_corr_threshold - float. If calculated feature-feature correlation is higher than this value,\n",
    "        one of the features will be added to features_to_drop dictionay\n",
    "    output: features_to_drop - dictionary with all the columns to drop\n",
    "    \n",
    "    \"\"\"\n",
    "    number_of_trials = 0\n",
    "    \n",
    "    # Total number of possible pairwise feature combinations. We would've have to calculate this many feature-feature\n",
    "    # correlations if we didn't check all the feature-target correlations.\n",
    "    full_number_of_trials = (len(features)**2 - len(features))/2\n",
    "    \n",
    "    # Iterating on all features pairwise combinations.\n",
    "    for feature_index_1 in range(len(features)):\n",
    "        feature_1 = features[feature_index_1]\n",
    "        \n",
    "        # Skip iteration if the feature is already in bad features.\n",
    "        if feature_1 in features_to_drop:\n",
    "            continue\n",
    "            \n",
    "        for feature_index_2 in range(feature_index_1+1, len(features)):\n",
    "            feature_2 = features[feature_index_2]\n",
    "            \n",
    "            # Skip iteration if the feature is already in bad features.\n",
    "            if feature_2 in features_to_drop:\n",
    "                continue \n",
    "            \n",
    "            # Feature correlations with target.\n",
    "            corr_with_target_f1 = abs(feature_target_corrs[feature_1])\n",
    "            corr_with_target_f2 = abs(feature_target_corrs[feature_2])\n",
    "            \n",
    "            # If feature correlations with target are close, then check feature-feature correlation.\n",
    "            # Main reason for checking correlations with target first - is to reduce number of feature-feature\n",
    "            # correlations computations.\n",
    "            if abs(corr_with_target_f1 - corr_with_target_f2) < target_corr_difference_threshold:\n",
    "                f1_f2_corr = data[[feature_1, feature_2]].corr(method='spearman').iloc[0][1]\n",
    "                number_of_trials+=1\n",
    "            \n",
    "                # If features are highly correlated, then add to bad features the one with lower target correlation.\n",
    "                if abs(f1_f2_corr)>features_corr_threshold:\n",
    "                    if corr_with_target_f1 >= corr_with_target_f2:\n",
    "                        features_to_drop[feature_2] = None\n",
    "                    else:\n",
    "                        features_to_drop[feature_1] = None\n",
    "                        \n",
    "    print ('Total number of possible pairwise feature combinations', full_number_of_trials)\n",
    "    print ('Actual number of calculations:', number_of_trials)\n",
    "    return features_to_drop\n",
    "\n",
    "features_to_drop_by_corrs = get_correlated_features(data=data\n",
    "                                            ,features=features\n",
    "                                            ,features_to_drop=features_to_drop\n",
    "                                            ,feature_target_corrs=feature_target_corrs\n",
    "                                            ,target_corr_difference_threshold=0.025\n",
    "                                            ,features_corr_threshold=0.99)\n",
    "print ()\n",
    "print ('Initial number of features:', len(features))\n",
    "print ('Features dropped:', len(features_to_drop_by_corrs))\n",
    "features_to_drop_by_corrs = list(features_to_drop_by_corrs.keys())\n",
    "\n",
    "features = list(set(features) - set(features_to_drop_by_corrs))\n",
    "print ('Current number of features:', len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trigram_all_jaccard_max_nostops', 'jac_stem', 'loc_country_match_relative', 'trigram_all_jaccard_stem', 'unigram_all_jaccard_max_src', 'q2_word_len_stem', 'f_Qratio_stem', 'q1_word_len_stem', 'unigram_jaccard_nostops', 'bigram_all_jaccard_max_stem', 'trigram_jaccard_stem', 'bigram_all_jaccard_stem', 'unigram_jaccard_src', 'unigram_jaccard_stem', 'bigram_all_jaccard_max_nostops', 'jaccard_dist_nbr_1', 'jac_nostops', 'loc_q1_country_num', 'trigram_all_jaccard_max_src', 'trigram_jaccard_nostops', 'jac_src', 'q2_char_len_src', 'unigram_all_jaccard_max_nostops', 'trigram_jaccard_src', 'bigram_all_jaccard_max_src', 'unigram_all_jaccard_max_stem', 'f_token_sort_stem', 'f_Qratio_nostops', 'trigram_all_jaccard_max_stem', 'q1_char_len_stem', 'f_Qratio_src', 'diffl_stem']\n"
     ]
    }
   ],
   "source": [
    "print (features_to_drop_by_corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection by CV score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate holdout scores, we'll split dataset into 5 folds by graph ids and will use lightgbm CV on resulting folds to get model score. For every feature we'll run lgb cv on all features except considered.\n",
    "\n",
    "If improevemnt is higher than threshold, then we'll remove feature from dataset immediately prior to testing remaining features. After each of iterations through all features we'll remove 1 feature with highest improvement below threshold level. Total number of iterations is set to be 3. If no new features were dropped after an iteration, process is stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "random_state = 0\n",
    "fold_indexes = []\n",
    "\n",
    "ids = pd.read_csv(os.path.join(DATA_PATH, 'train_ids.csv'), usecols=['graph_id'])#[:100000]\n",
    "graph_ids_unique = ids.graph_id.unique()\n",
    "\n",
    "kf = KFold(n_splits = n_splits, shuffle = True, random_state = random_state)\n",
    "for train_graphs, test_graphs in list(kf.split(graph_ids_unique)):\n",
    "    train_ind = ids[ids.graph_id.isin(graph_ids_unique[train_graphs])].index.values\n",
    "    test_ind  = ids[ids.graph_id.isin(graph_ids_unique[test_graphs ])].index.values\n",
    "    fold_indexes.append([train_ind, test_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def get_score(params, features):\n",
    "    \"\"\"\n",
    "    params - dictionary, parameters for lgb model\n",
    "    Also uses global variables: data (pandas DataFrame), target (numpy array), n_splits and random_state (integers),\n",
    "    fold_indexes - list of lists with train and test indexes for each fold\n",
    "    \n",
    "    ouptut: cv logloss score and cv std\n",
    "    \"\"\"\n",
    "    dtrain = lgb.Dataset(data[features], target, max_bin=params['max_bin'])\n",
    "    \n",
    "    cvmodel = lgb.cv(params, \n",
    "                     dtrain,\n",
    "                     num_boost_round=10000, \n",
    "                     folds = fold_indexes, \n",
    "                     early_stopping_rounds=15,\n",
    "                     verbose_eval=False)\n",
    "    score = cvmodel['binary_logloss-mean'][-1]\n",
    "    return score\n",
    "\n",
    "initial_params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', \n",
    "                'metric': 'binary_logloss', 'learning_rate': 0.05, 'max_bin':255}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(cvmodel, max_num_features=100, figsize=(15, 20), importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20996 - initial base score \n",
      "\n",
      "Start of iteration 1\n",
      "Result of iteration 1\n",
      "0.20958 ['pos_diff_end_src'] \n",
      "\n",
      "Start of iteration 2\n",
      "Result of iteration 2\n",
      "0.2095 ['pos_diff_end_src', 'q1_char_len_nostops'] \n",
      "\n",
      "CPU times: user 9d 59min 32s, sys: 12h 43min 28s, total: 9d 13h 43min\n",
      "Wall time: 2d 9h 15min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_score = get_score(initial_params, list(set(features)))\n",
    "print (round(base_score,5), '- initial base score \\n')\n",
    "\n",
    "features_to_drop = []\n",
    "total_iterations=2\n",
    "\n",
    "for iter_num in range(1, total_iterations+1):\n",
    "    print ('Start of iteration', iter_num)\n",
    "    imprvs = dict()\n",
    "    features_to_drop_starting_length = len(features_to_drop)\n",
    "    \n",
    "    for f in features:\n",
    "        feature_subset = list(set(features) - set(features_to_drop) - set([f]))\n",
    "        score = get_score(initial_params, feature_subset)\n",
    "        improvement = base_score - score\n",
    "        \n",
    "        # If improvement higher than threshold, then remove feature immediately and recalculate base scores. \n",
    "        # Else - add it to the dict, from which we'll delete the feature with highest improvement \n",
    "        # at the end of iteration.\n",
    "        if improvement>0.0005/iter_num:\n",
    "            features_to_drop.append(f)\n",
    "            base_score = score\n",
    "            print (round(base_score,5), f, round(improvement, 5))\n",
    "        else:\n",
    "            imprvs[f] = score\n",
    "\n",
    "    # Take the worst feature from imprvs dict and add it to bad features, if improvement > 0\n",
    "    if len(imprvs)>0:\n",
    "        best_impr = sorted(imprvs.items(), key=lambda x: x[1])[0]\n",
    "        feature = best_impr[0]\n",
    "        if best_impr[1]<base_score and feature not in features_to_drop:\n",
    "            features_to_drop.append(feature)\n",
    "    \n",
    "    # Update the base scores\n",
    "    feature_subset = list(set(features)-set(features_to_drop))\n",
    "    base_score = get_score(initial_params, feature_subset)\n",
    "    print ('Result of iteration', iter_num)\n",
    "    print (round(base_score,5), features_to_drop, '\\n')\n",
    "    \n",
    "    # If no features were added in iteration - break process\n",
    "    if features_to_drop_starting_length - len(features_to_drop)==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now do the reverse process - restore features back from dropped, if by adding them our score has improved. Other algorithms details are essentially the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2095 - initial base score \n",
      "\n",
      "Start of iteration 1\n",
      "Result of iteration 1\n",
      "0.2095 ['jaccard_dist_nbr_1'] \n",
      "\n",
      "Start of iteration 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4796e5a9ff47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"print (round(base_score,5), '- initial base score \\\\n')\\n\\ntotal_iterations=3\\nfeatures_to_return = []\\n\\nfor iter_num in range(1,total_iterations+1):\\n    print ('Start of iteration', iter_num)\\n    imprvs = dict()\\n    features_to_return_starting_length = len(features_to_return)\\n    \\n    for f in list(set(features_to_drop+features_to_drop_by_corrs) - set(features_to_return)):\\n        feature_subset = list(set(features) - set(features_to_drop+features_to_drop_by_corrs))\\\\\\n                             + features_to_return + [f]\\n        score = get_score(initial_params, feature_subset)      \\n        improvement = base_score - score\\n        \\n        # If improvement higher than threshold, then restore feature immediately and recalculate base scores. \\n        # Else - add it to the dict, from which we'll restore the feature with highest improvement \\n        # at the end of iteration.\\n        if improvement>0.0005/iter_num:\\n            features_to_return.append(f)\\n            base_score = score\\n            print (round(score,5), f, round(improvement, 5))\\n        else:\\n            imprvs[f] = score\\n            \\n    # Take the best feature from imprvs dict and eturn it if improvement > 0\\n    if len(imprvs)>0:\\n        best_impr = sorted(imprvs.items(), key=lambda x: x[1])[0]\\n        feature = best_impr[0]\\n        if best_impr[1]<base_score and feature not in features_to_return:\\n            features_to_return.append(feature)\\n    \\n    # Update the base scores        \\n    feature_subset = list(set(features) - set(features_to_drop+features_to_drop_by_corrs)) + features_to_return\\n    base_score = get_score(initial_params, feature_subset)\\n    print ('Result of iteration', iter_num)\\n    print (round(base_score,5), features_to_return, '\\\\n')\\n    \\n    # If no features were added in iteration - break process\\n    if features_to_return_starting_length - len(features_to_return)==0:\\n        break\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-257e587fd476>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(params, features)\u001b[0m\n\u001b[1;32m     16\u001b[0m                      \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold_indexes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                      \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                      verbose_eval=False)\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_logloss-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    441\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    442\u001b[0m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandlerFunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandlerFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1524\u001b[0m             \u001b[0mEvaluation\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \"\"\"\n\u001b[0;32m-> 1526\u001b[0;31m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   1527\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \"\"\"\n\u001b[1;32m   1526\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 1527\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Denis/anaconda/envs/python3/lib/python3.5/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   1750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (round(base_score,5), '- initial base score \\n')\n",
    "\n",
    "total_iterations=3\n",
    "features_to_return = []\n",
    "\n",
    "for iter_num in range(1,total_iterations+1):\n",
    "    print ('Start of iteration', iter_num)\n",
    "    imprvs = dict()\n",
    "    features_to_return_starting_length = len(features_to_return)\n",
    "    \n",
    "    for f in list(set(features_to_drop+features_to_drop_by_corrs) - set(features_to_return)):\n",
    "        feature_subset = list(set(features) - set(features_to_drop+features_to_drop_by_corrs))\\\n",
    "                             + features_to_return + [f]\n",
    "        score = get_score(initial_params, feature_subset)      \n",
    "        improvement = base_score - score\n",
    "        \n",
    "        # If improvement higher than threshold, then restore feature immediately and recalculate base scores. \n",
    "        # Else - add it to the dict, from which we'll restore the feature with highest improvement \n",
    "        # at the end of iteration.\n",
    "        if improvement>0.0005/iter_num:\n",
    "            features_to_return.append(f)\n",
    "            base_score = score\n",
    "            print (round(score,5), f, round(improvement, 5))\n",
    "        else:\n",
    "            imprvs[f] = score\n",
    "            \n",
    "    # Take the best feature from imprvs dict and eturn it if improvement > 0\n",
    "    if len(imprvs)>0:\n",
    "        best_impr = sorted(imprvs.items(), key=lambda x: x[1])[0]\n",
    "        feature = best_impr[0]\n",
    "        if best_impr[1]<base_score and feature not in features_to_return:\n",
    "            features_to_return.append(feature)\n",
    "    \n",
    "    # Update the base scores        \n",
    "    feature_subset = list(set(features) - set(features_to_drop+features_to_drop_by_corrs)) + features_to_return\n",
    "    base_score = get_score(initial_params, feature_subset)\n",
    "    print ('Result of iteration', iter_num)\n",
    "    print (round(base_score,5), features_to_return, '\\n')\n",
    "    \n",
    "    # If no features were added in iteration - break process\n",
    "    if features_to_return_starting_length - len(features_to_return)==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ('Features removed by correlations:', features_to_drop_by_corrs, '\\n')\n",
    "print ('Features removed by holdout scoring:', features_to_drop, '\\n')\n",
    "print ('Features restored by holdout scoring:', features_to_return, '\\n')\n",
    "features_to_drop_final = list(set(features_to_drop_by_corrs+features_to_drop) - set(features_to_return))\n",
    "print ('Final features to drop:', features_to_drop_final)\n",
    "features = list(set(features) - set(features_to_drop_by_corrs+features_to_drop)) + features_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'bad_features.pkl'), 'wb') as F:\n",
    "    pickle.dump(features_to_drop_final, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
    "\n",
    "def get_score(params):\n",
    "    \"\"\"\n",
    "    params - dictionary, parameters for lgb model\n",
    "    Also uses global variables: data (pandas DataFrame), target (numpy array), n_splits and random_state (integers).\n",
    "    \n",
    "    ouptut: mean logloss score of two predicitons\n",
    "    \"\"\"\n",
    "    dtrain = lgb.Dataset(data[features], target, max_bin=params['max_bin'])\n",
    "    \n",
    "    cvmodel = lgb.cv(params, \n",
    "                     dtrain,\n",
    "                     num_boost_round=10000, \n",
    "                     folds = fold_indexes, \n",
    "                     early_stopping_rounds=15,\n",
    "                     verbose_eval=False)\n",
    "    score = cvmodel['binary_logloss-mean'][-1]\n",
    "    \n",
    "    try:\n",
    "        if len(trials.trials)%10==0:\n",
    "            print ('{} trials are done in {} minutes. Minimal loss achieved is {}'\n",
    "                   .format(len(trials.trials), round((time.time()-t_start)/60,1),\n",
    "                           min(map(lambda trial: round(trial['result']['loss'], 4), trials.trials[:-1])))\n",
    "                  )\n",
    "    except:\n",
    "        pass\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_TRIALS = 100\n",
    "\n",
    "initial_params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', \n",
    "                  'metric': 'binary_logloss', 'learning_rate': 0.05, 'max_bin':255}\n",
    "\n",
    "initial_params_score = get_score(initial_params)\n",
    "print ('Default parameters score:', round(initial_params_score, 4))\n",
    "\n",
    "# Define parameters space for hyperopt to search \n",
    "search_space = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', \n",
    "                'metric': 'binary_logloss', 'learning_rate': 0.05,\n",
    "                \n",
    "                'num_leaves': hp.choice('num_leaves', 2**np.arange(2,12,1)),\n",
    "                #'feature_fraction': hp.uniform('feature_fraction', low=0.5, high=1),\n",
    "                'bagging_fraction': hp.choice('bagging_fraction', np.arange(0.75, 1.01, 0.05)),\n",
    "                'feature_fraction': hp.choice('feature_fraction', np.arange(0.75, 1.01, 0.05)),\n",
    "                #'bagging_fraction': hp.uniform('bagging_fraction', low=0.5, high=1),\n",
    "                'bagging_freq':     hp.choice('bagging_freq', np.arange(1, 11, 1, dtype=int)),\n",
    "                'min_data_in_leaf': hp.choice('min_data_in_leaf', np.arange(1, 91, 10, dtype=int)),\n",
    "                'lambda_l2'        :hp.choice('lambda_l2', [0,1]),\n",
    "                'min_gain_to_split':hp.choice('min_gain_to_split', [0, 1, 3, 5]),\n",
    "                'max_bin': hp.choice('max_bin', [100,200,250,300,400,500])\n",
    "               }\n",
    "\n",
    "t_start = time.time()\n",
    "trials = Trials()\n",
    "best = fmin(get_score,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=MAX_TRIALS,\n",
    "            trials=trials\n",
    "           )\n",
    "\n",
    "best_params = space_eval(search_space, best)\n",
    "print ('Best parameters found:')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "#xs = [t['misc']['vals']['bagging_fraction'] for t in trials.trials[:-1]]\n",
    "xs = [t['misc']['tid'] for t in trials.trials[:-1]]\n",
    "ys = [t['result']['loss'] for t in trials.trials[:-1]]\n",
    "\n",
    "plt.scatter(xs, ys, s=30, label='hyperopt trials')\n",
    "plt.axhline(y=initial_params_score, linestyle='--', label='default parameters')\n",
    "plt.legend(frameon=True, framealpha=1)\n",
    "plt.title('Trials loss progression')\n",
    "plt.xlabel('Trial number')\n",
    "plt.ylabel('Holdout logloss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'lgb_best_params.pkl'), 'wb') as F:\n",
    "    pickle.dump(best_params, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
